{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFr2ZVsBmZAK"
      },
      "source": [
        "# SFW Classifier - Content Moderation Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbtIGzgPmZAN",
        "outputId": "57636865-5aa8-40ae-e54e-536c0865fe2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymongo\n",
            "  Downloading pymongo-4.15.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo)\n",
            "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Downloading pymongo-4.15.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m331.1/331.1 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: dnspython, pymongo\n",
            "Successfully installed dnspython-2.8.0 pymongo-4.15.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pymongo\n",
        "\n",
        "import os\n",
        "from pymongo import MongoClient\n",
        "import pandas as pd\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import json\n",
        "from datetime import datetime\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rJ2G6nt-mZAO"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UvWQePOWmZAO"
      },
      "outputs": [],
      "source": [
        "# MongoDB Configuration\n",
        "MONGO_URI = os.getenv('MONGO_URI', 'mongodb://localhost:27017/')\n",
        "DATABASE_NAME = os.getenv('MONGO_DATABASE', 'your_database')\n",
        "COLLECTION_NAME = os.getenv('MONGO_COLLECTION', 'your_collection')\n",
        "\n",
        "# Gemini Configuration\n",
        "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY', '')\n",
        "\n",
        "# Content Moderation System Prompt\n",
        "SYSTEM_PROMPT = \"You are an expert data labeler specializing in content classification. Your task is to analyze conversation snippets and assign soft labels based on the level of sexual or intimate content, providing a probability distribution across a defined set of categories.\"\n",
        "\n",
        "# Classification Prompt Template\n",
        "PROMPT_TEMPLATE = \"\"\"You will be provided with a conversation history. Your task is to analyze the entire conversation for context but focus primarily on the **last message** to classify its content.\n",
        "\n",
        "**User Input:**\n",
        "Here is the conversation history:\n",
        "{conversation_history}\n",
        "\n",
        "**Classification Scale:**\n",
        "1.  **SFW:** No sexual or intimate content.\n",
        "2.  **Mildly Suggestive:** Light romance or flirtation; non-graphic.\n",
        "3.  **Moderately Intimate:** Erotic situations without explicit sexual acts.\n",
        "4.  **Explicit NSFW:** Graphic depiction of sexual acts or anatomy.\n",
        "5.  **Illegal / Extreme NSFW:** Prohibited content (e.g., involving minors, non-consensual acts).\n",
        "\n",
        "**Output Instructions:**\n",
        "1.  Your response must be a single JSON object representing a probability distribution (soft labels) of which category the content belongs to.\n",
        "2.  The keys of the JSON object must be the following strings: \"SFW\", \"Mildly Suggestive\", \"Moderately Intimate\", \"Explicit NSFW\", \"Illegal / Extreme NSFW\".\n",
        "3.  The value for each key must be a floating-point number between 0.0 and 1.0, representing the probability for that category.\n",
        "4.  The sum of all probability values in the dictionary must equal 1.0.\n",
        "5.  Your final output must ONLY be the JSON object. Do not include any other text, explanations, or markdown formatting like ```json.\n",
        "\n",
        "**Example Output Format:**\n",
        "```json\n",
        "{\n",
        "  \"SFW\": 0.1,\n",
        "  \"Mildly Suggestive\": 0.7,\n",
        "  \"Moderately Intimate\": 0.2,\n",
        "  \"Explicit NSFW\": 0.0,\n",
        "  \"Illegal / Extreme NSFW\": 0.0\n",
        "}\n",
        "```\"\"\"\n",
        "\n",
        "# Processing Configuration\n",
        "NUM_ROWS = 100000  # Number of rows to fetch from MongoDB\n",
        "OUTPUT_FILE = f'sfw_classification_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.parquet'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r-BDUdIGmZAP"
      },
      "source": [
        "## 1. Connect to MongoDB and Fetch Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jiZCwz5fmZAP"
      },
      "outputs": [],
      "source": [
        "def fetch_data_from_mongodb(uri, db_name, collection_name, limit=100000):\n",
        "    \"\"\"Fetch data from MongoDB collection\"\"\"\n",
        "    client = MongoClient(uri)\n",
        "    db = client[db_name]\n",
        "    collection = db[collection_name]\n",
        "\n",
        "    # Fetch documents\n",
        "    documents = list(collection.find().limit(limit))\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(documents)\n",
        "\n",
        "    client.close()\n",
        "    print(f\"Fetched {len(df)} rows from MongoDB\")\n",
        "    return df\n",
        "\n",
        "# Fetch data\n",
        "df = fetch_data_from_mongodb(MONGO_URI, DATABASE_NAME, COLLECTION_NAME, NUM_ROWS)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyUSAinjmZAP"
      },
      "source": [
        "## 2. Prepare Batch Request File (JSONL)\n",
        "Create a JSONL file with all requests for Gemini Batch API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-446vK5umZAQ"
      },
      "outputs": [],
      "source": [
        "def format_conversation_history(conversation_array):\n",
        "    \"\"\"Format conversation history with role labels\"\"\"\n",
        "    # Take last 6 messages (or fewer if less available)\n",
        "    last_messages = conversation_array[-6:] if len(conversation_array) >= 6 else conversation_array\n",
        "\n",
        "    formatted_messages = []\n",
        "    for msg in last_messages:\n",
        "        role = msg.get('role', 'unknown')\n",
        "        content = msg.get('content', '')\n",
        "        formatted_messages.append(f\"{role.upper()}: {content}\")\n",
        "\n",
        "    # Use newline separator for readability\n",
        "    return \"\\n\".join(formatted_messages)\n",
        "\n",
        "def create_batch_requests_file(df, conversation_column, prompt_template, system_prompt, output_file='batch_requests.jsonl'):\n",
        "    \"\"\"Create JSONL file with batch requests for Gemini API\"\"\"\n",
        "    with open(output_file, 'w') as f:\n",
        "        for idx, row in df.iterrows():\n",
        "            conversation_array = row[conversation_column]\n",
        "            conversation_history = format_conversation_history(conversation_array)\n",
        "            user_prompt = prompt_template.format(conversation_history=conversation_history)\n",
        "\n",
        "            request = {\n",
        "                \"key\": f\"request-{idx}\",\n",
        "                \"request\": {\n",
        "                    \"system_instruction\": {\n",
        "                        \"parts\": [{\"text\": system_prompt}]\n",
        "                    },\n",
        "                    \"contents\": [{\n",
        "                        \"parts\": [{\"text\": user_prompt}],\n",
        "                        \"role\": \"user\"\n",
        "                    }],\n",
        "                    \"generation_config\": {\n",
        "                        \"temperature\": 0.0,\n",
        "                        \"max_output_tokens\": 200,\n",
        "                        \"response_modalities\": [\"TEXT\"],\n",
        "                        \"response_mime_type\": \"application/json\"\n",
        "                    },\n",
        "                    \"thinking_config\": {\n",
        "                        \"thinking_budget\": 0\n",
        "                    },\n",
        "                    \"safety_settings\": [\n",
        "                        {\n",
        "                            \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
        "                            \"threshold\": \"OFF\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "                            \"threshold\": \"OFF\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "                            \"threshold\": \"OFF\"\n",
        "                        },\n",
        "                        {\n",
        "                            \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
        "                            \"threshold\": \"OFF\"\n",
        "                        }\n",
        "                    ]\n",
        "                },\n",
        "                \"metadata\": {\n",
        "                    \"original_id\": str(row.get('_id', idx)),\n",
        "                    \"index\": idx\n",
        "                }\n",
        "            }\n",
        "            f.write(json.dumps(request) + '\\n')\n",
        "\n",
        "    print(f\"Created batch requests file: {output_file} with {len(df)} requests\")\n",
        "    return output_file\n",
        "\n",
        "# Create batch requests (update 'conversation_column' to your actual column name)\n",
        "# batch_file = create_batch_requests_file(df, conversation_column='conversation_history', prompt_template=PROMPT_TEMPLATE, system_prompt=SYSTEM_PROMPT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZT6g_iXVmZAQ"
      },
      "source": [
        "## 3. Submit Batch Job to Gemini API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPMTHFvBmZAQ"
      },
      "outputs": [],
      "source": [
        "# Initialize Gemini client\n",
        "client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "def submit_batch_job(client, batch_file, model=\"gemini-2.5-flash-preview-09-2025\"):\n",
        "    \"\"\"Upload batch file and create batch job\"\"\"\n",
        "\n",
        "    # Upload the batch requests file\n",
        "    print(f\"Uploading {batch_file}...\")\n",
        "    uploaded_file = client.files.upload(\n",
        "        file=batch_file,\n",
        "        config={'display_name': 'sfw-classification-batch', 'mime_type': 'application/jsonl'}\n",
        "    )\n",
        "    print(f\"Uploaded file: {uploaded_file.name}\")\n",
        "\n",
        "    # Create batch job\n",
        "    print(\"Creating batch job...\")\n",
        "    batch_job = client.batches.create(\n",
        "        model=f\"models/{model}\",\n",
        "        src=uploaded_file.name,\n",
        "        config={\n",
        "            'display_name': f\"sfw-classifier-{datetime.now().strftime('%Y%m%d_%H%M%S')}\",\n",
        "        }\n",
        "    )\n",
        "\n",
        "    print(f\"Batch job created: {batch_job.name}\")\n",
        "    print(f\"Job state: {batch_job.state.name}\")\n",
        "    print(f\"\\n⚠️ SAVE THIS JOB ID: {batch_job.name}\")\n",
        "\n",
        "    return batch_job\n",
        "\n",
        "# Submit batch job\n",
        "# batch_job = submit_batch_job(client, batch_file)\n",
        "# JOB_ID = batch_job.name  # Save this for later!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL5gYaCMmZAQ"
      },
      "source": [
        "## 4. Monitor Batch Job Status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wx_fQAbNmZAQ"
      },
      "outputs": [],
      "source": [
        "# If you need to reconnect, reinitialize the client\n",
        "# client = genai.Client(api_key=GEMINI_API_KEY)\n",
        "\n",
        "def check_batch_status(job_id, api_key=None):\n",
        "    \"\"\"Check the status of a batch job using job ID\"\"\"\n",
        "    if api_key is None:\n",
        "        api_key = GEMINI_API_KEY\n",
        "\n",
        "    client = genai.Client(api_key=api_key)\n",
        "    job = client.batches.get(name=job_id)\n",
        "    print(f\"Job: {job.name}\")\n",
        "    print(f\"State: {job.state.name}\")\n",
        "    print(f\"Create time: {job.create_time}\")\n",
        "    if hasattr(job, 'update_time'):\n",
        "        print(f\"Update time: {job.update_time}\")\n",
        "    return job\n",
        "\n",
        "def wait_for_batch_completion(job_id, api_key=None, check_interval=60):\n",
        "    \"\"\"Wait for batch job to complete (checks every check_interval seconds)\"\"\"\n",
        "    if api_key is None:\n",
        "        api_key = GEMINI_API_KEY\n",
        "\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    while True:\n",
        "        job = client.batches.get(name=job_id)\n",
        "        print(f\"Current state: {job.state.name}\")\n",
        "\n",
        "        if job.state.name == 'JOB_STATE_SUCCEEDED':\n",
        "            print(\"Batch job completed successfully!\")\n",
        "            return job\n",
        "        elif job.state.name in ['JOB_STATE_FAILED', 'JOB_STATE_CANCELLED']:\n",
        "            print(f\"Batch job {job.state.name}\")\n",
        "            return job\n",
        "\n",
        "        print(f\"Waiting {check_interval} seconds before next check...\")\n",
        "        time.sleep(check_interval)\n",
        "\n",
        "# Check status using saved job ID\n",
        "# JOB_ID = \"your-job-id-here\"  # Paste your job ID here\n",
        "# check_batch_status(JOB_ID)\n",
        "\n",
        "# Or wait for completion\n",
        "# completed_job = wait_for_batch_completion(JOB_ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYMu1wyXmZAR"
      },
      "source": [
        "## 5. Retrieve and Process Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "som2UZ3LmZAR"
      },
      "outputs": [],
      "source": [
        "def download_batch_results(job, api_key=None):\n",
        "    \"\"\"Download and parse batch job results\"\"\"\n",
        "    if api_key is None:\n",
        "        api_key = GEMINI_API_KEY\n",
        "\n",
        "    client = genai.Client(api_key=api_key)\n",
        "\n",
        "    # If job is a string (job_id), fetch the job object\n",
        "    if isinstance(job, str):\n",
        "        job = client.batches.get(name=job)\n",
        "\n",
        "    if job.state.name != 'JOB_STATE_SUCCEEDED':\n",
        "        print(f\"Job not successful. Current state: {job.state.name}\")\n",
        "        return None\n",
        "\n",
        "    # Get result file name\n",
        "    result_file_name = job.output.file_name if hasattr(job, 'output') else job.dest.file_name\n",
        "\n",
        "    # Download results\n",
        "    print(f\"Downloading results from: {result_file_name}\")\n",
        "    file_content_bytes = client.files.download(file=result_file_name)\n",
        "    file_content = file_content_bytes.decode('utf-8')\n",
        "\n",
        "    # Parse JSONL results\n",
        "    results = []\n",
        "    for line in file_content.splitlines():\n",
        "        if line.strip():\n",
        "            result = json.loads(line)\n",
        "            results.append(result)\n",
        "\n",
        "    print(f\"Downloaded {len(results)} results\")\n",
        "    return results\n",
        "\n",
        "def extract_last_messages(conversation_array, num_messages=6):\n",
        "    \"\"\"Extract last N messages from conversation history\"\"\"\n",
        "    last_messages = conversation_array[-num_messages:] if len(conversation_array) >= num_messages else conversation_array\n",
        "    formatted = []\n",
        "    for msg in last_messages:\n",
        "        role = msg.get('role', 'unknown')\n",
        "        content = msg.get('content', '')\n",
        "        formatted.append(f\"{role.upper()}: {content}\")\n",
        "    return \"\\n---\\n\".join(formatted)\n",
        "\n",
        "def parse_results_to_dataframe(results, original_df, conversation_column='conversation_history'):\n",
        "    \"\"\"Convert batch results to a clean DataFrame with soft label probabilities and last 6 messages\"\"\"\n",
        "    parsed_results = []\n",
        "\n",
        "    for result in results:\n",
        "        request_key = result.get('key', '')\n",
        "        metadata = result.get('metadata', {})\n",
        "        idx = metadata.get('index')\n",
        "\n",
        "        # Extract response text (JSON soft labels)\n",
        "        soft_labels = None\n",
        "        raw_response = None\n",
        "        if 'response' in result:\n",
        "            candidates = result['response'].get('candidates', [])\n",
        "            if candidates:\n",
        "                content = candidates[0].get('content', {})\n",
        "                parts = content.get('parts', [])\n",
        "                if parts:\n",
        "                    raw_response = parts[0].get('text', '').strip()\n",
        "                    # Try to parse as JSON\n",
        "                    try:\n",
        "                        soft_labels = json.loads(raw_response)\n",
        "                    except json.JSONDecodeError:\n",
        "                        soft_labels = None\n",
        "\n",
        "        # Get last 6 messages from original data\n",
        "        last_6_messages = \"\"\n",
        "        if idx is not None and idx < len(original_df):\n",
        "            conversation_array = original_df.iloc[idx][conversation_column]\n",
        "            last_6_messages = extract_last_messages(conversation_array, num_messages=6)\n",
        "\n",
        "        # Extract individual probabilities\n",
        "        prob_sfw = soft_labels.get('SFW', None) if soft_labels else None\n",
        "        prob_mildly_suggestive = soft_labels.get('Mildly Suggestive', None) if soft_labels else None\n",
        "        prob_moderately_intimate = soft_labels.get('Moderately Intimate', None) if soft_labels else None\n",
        "        prob_explicit_nsfw = soft_labels.get('Explicit NSFW', None) if soft_labels else None\n",
        "        prob_illegal_extreme = soft_labels.get('Illegal / Extreme NSFW', None) if soft_labels else None\n",
        "\n",
        "        parsed_results.append({\n",
        "            'request_key': request_key,\n",
        "            'original_id': metadata.get('original_id'),\n",
        "            'index': idx,\n",
        "            'last_6_messages': last_6_messages,\n",
        "            'prob_sfw': prob_sfw,\n",
        "            'prob_mildly_suggestive': prob_mildly_suggestive,\n",
        "            'prob_moderately_intimate': prob_moderately_intimate,\n",
        "            'prob_explicit_nsfw': prob_explicit_nsfw,\n",
        "            'prob_illegal_extreme': prob_illegal_extreme,\n",
        "            'raw_response': raw_response,\n",
        "            'status': result.get('status', {})\n",
        "        })\n",
        "\n",
        "    results_df = pd.DataFrame(parsed_results)\n",
        "    results_df = results_df.sort_values('index').reset_index(drop=True)\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# Download and parse results using job ID\n",
        "# JOB_ID = \"your-job-id-here\"\n",
        "# results = download_batch_results(JOB_ID)\n",
        "# results_df = parse_results_to_dataframe(results, df, conversation_column='conversation_history')\n",
        "# results_df.head()\n",
        "\n",
        "# View probability distributions\n",
        "# print(results_df[['prob_sfw', 'prob_mildly_suggestive', 'prob_moderately_intimate', 'prob_explicit_nsfw', 'prob_illegal_extreme']].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuahtVOTmZAR"
      },
      "source": [
        "## 6. Save Results to Flatfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Obw8zLShmZAR"
      },
      "outputs": [],
      "source": [
        "# Save to Parquet (recommended - handles text data well)\n",
        "# columns_to_save = ['last_6_messages', 'prob_sfw', 'prob_mildly_suggestive', 'prob_moderately_intimate', 'prob_explicit_nsfw', 'prob_illegal_extreme']\n",
        "# results_df[columns_to_save].to_parquet(OUTPUT_FILE, index=False, compression='snappy')\n",
        "# print(f\"Results saved to {OUTPUT_FILE}\")\n",
        "\n",
        "# Alternative: Save to JSONL (preserves structure better)\n",
        "# results_df[columns_to_save].to_json(OUTPUT_FILE.replace('.parquet', '.jsonl'), orient='records', lines=True)\n",
        "\n",
        "# View sample output\n",
        "# print(results_df[columns_to_save].head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}